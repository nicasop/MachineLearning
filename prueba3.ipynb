{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALEXIS VILLAVICENCIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.cluster import adjusted_rand_score,adjusted_mutual_info_score,normalized_mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import davies_bouldin_score,silhouette_score\n",
    "#pip install validclust ##instalar la libreria validclust\n",
    "from validclust import dunn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importarCSV(nombre_file):\n",
    "    return pd.read_csv(nombre_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Realizar el agrupamiento mediante dos algoritmos diferentes. Para cada caso indicar la etiqueta que correspondería al grupo respectivo, e.g. (0 = VIP, 2 = VIP Potencial, 1 = Nuevos, 3 = Baja Frecuencia…) (4 puntos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = importarCSV('segmentation_data.csv')\n",
    "num_grupos = 4\n",
    "dataset = datos.iloc[:,1:4]\n",
    "print(dataset)\n",
    "distancias = euclidean_distances(dataset)#matriz de distancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 ... 0 0 0]\n",
      "[2 2 2 ... 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "##KMEANS\n",
    "kmeans = KMeans(n_clusters=num_grupos,\n",
    "                random_state=0,\n",
    "                max_iter=500) \n",
    "\n",
    "##DHC\n",
    "hc = AgglomerativeClustering(n_clusters=num_grupos, \n",
    "                        affinity = 'precomputed', \n",
    "                        linkage = 'complete')\n",
    "\n",
    "##Predicciones\n",
    "clusters_k = kmeans.fit_predict(dataset)\n",
    "clusters_dhc = hc.fit_predict(distancias)\n",
    "\n",
    "print(clusters_k)\n",
    "print(clusters_dhc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMEANS\n",
      "0 --- 4043\n",
      "1 --- 101\n",
      "2 --- 14\n",
      "3 --- 689\n",
      "\n",
      "DHC\n",
      "0 --- 46\n",
      "1 --- 5\n",
      "2 --- 4\n",
      "3 --- 4792\n"
     ]
    }
   ],
   "source": [
    "num_grupos = np.unique(clusters_k,return_counts=True)\n",
    "num_grupos1 = np.unique(clusters_dhc,return_counts=True)\n",
    "print('KMEANS')\n",
    "for i in range(len(num_grupos[0])):\n",
    "    print(num_grupos[0][i],'---',num_grupos[1][i])\n",
    "\n",
    "print('\\nDHC')\n",
    "for i in range(len(num_grupos1[0])):\n",
    "    print(num_grupos1[0][i],'---',num_grupos1[1][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Etiquetado de los resultados obtenidos\n",
    "#Considerando las caracteristicas descritas de cada grupo acerca de los valores de frequency, recency y monetary. El etiquetado de los clusters se va a distribuir de la siguiente manera\n",
    "#El grupo con el menor número de instancias va a ser el grupo de Clientes Vip con el etiqueta CVip ya que considero que la tienda tiene muy pocos clientes vip comparados con el resto de clientes.\n",
    "#El grupo que le sigue en el número de instancias va a ser el grupo de Vips Potenciales con la etiqueta PVip ya que considero que este grupo debe tener mas instancias que el grupo vip\n",
    "#El grupo que le sigue serian los clientes Nuevos con la etiqueta CNuevos ya que este grupo va a tener mas instancias que los dos anterios pero considero que no tantas como el último grupo ya que el último grupo que es el de clientes con baja frecuencia con la etiqueta BAFrecuencia engloblan clientes que ya no van a ir nunca más o que van muy derepente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CVip' 'CVip' 'CVip' ... 'BAFrecuencia' 'BAFrecuencia' 'BAFrecuencia']\n",
      "['CVip' 'CVip' 'CVip' ... 'BAFrecuencia' 'BAFrecuencia' 'BAFrecuencia']\n"
     ]
    }
   ],
   "source": [
    "##Tomando en cuenta la explicación anterior y el número de instancias en cada cluster el etiquetado seria el siguiente\n",
    "\n",
    "## etiquetado KMEANS\n",
    "clus_K = pd.DataFrame(clusters_k)\n",
    "clus_K[0][clus_K[0]==0] = 'BAFrecuencia'\n",
    "clus_K[0][clus_K[0]==1] = 'PVip'\n",
    "clus_K[0][clus_K[0]==2] = 'CVip'\n",
    "clus_K[0][clus_K[0]==3] = 'CNuevos'\n",
    "\n",
    "clus_K = np.array(clus_K[0])\n",
    "print(clus_K)\n",
    "\n",
    "##  etiquetado DHC\n",
    "clus_dhc = pd.DataFrame(clusters_dhc)\n",
    "clus_dhc[0][clus_dhc[0]==0] = 'CNuevos'\n",
    "clus_dhc[0][clus_dhc[0]==1] = 'PVip'\n",
    "clus_dhc[0][clus_dhc[0]==2] = 'CVip'\n",
    "clus_dhc[0][clus_dhc[0]==3] = 'BAFrecuencia'\n",
    "\n",
    "clus_dhc = np.array(clus_dhc[0])\n",
    "print(clus_dhc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultadoKMEANS = pd.DataFrame({'clientes':datos['client'],'grupo':clus_K})\n",
    "resultadoDHC = pd.DataFrame({'clientes':datos['client'],'grupo':clus_dhc})\n",
    "\n",
    "print('KMEANS')\n",
    "print(resultadoKMEANS)\n",
    "print('DHC')\n",
    "print(resultadoDHC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Comparar el rendimiento de los resultados del literal anterior mediante TODAS las métricas que conoce (2 puntos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- RENDIMIENTO DEL ALGORITMO DE KMEANS -------\n",
      "Indice de DUNN KMEANS:  0.0006735291068264448\n",
      "Coeficiente de Siluheta de KMEANS: 0.5870340967555622\n",
      "\n",
      "-------- RENDIMIENTO DEL ALGORITMO DE DHC -------\n",
      "Indice de DUNN DHC:  0.02412916532627877\n",
      "Coeficiente de Siluheta de DHC: 0.8585806948033449\n"
     ]
    }
   ],
   "source": [
    "print('-------- RENDIMIENTO DEL ALGORITMO DE KMEANS -------')\n",
    "#KMEANS\n",
    "dunn_k = dunn(distancias,clus_K)\n",
    "print('Indice de DUNN KMEANS: ',dunn_k)\n",
    "si1_dhc = silhouette_score(distancias, clus_K, metric='precomputed')#coefiente de silueta a partir de la matriz de distancias\n",
    "print('Coeficiente de Siluheta de KMEANS:',si1_dhc)\n",
    "\n",
    "print('\\n-------- RENDIMIENTO DEL ALGORITMO DE DHC -------')\n",
    "#DHC\n",
    "dunn_dhc = dunn(distancias,clus_dhc)\n",
    "print('Indice de DUNN DHC: ',dunn_dhc)\n",
    "si1_dhc = silhouette_score(distancias, clus_dhc, metric='precomputed')#coefiente de silueta a partir de la matriz de distancias\n",
    "print('Coeficiente de Siluheta de DHC:',si1_dhc)\n",
    "\n",
    "## No se pudo realizar la validación externa de cada uno de los algoritmos (kmeans y dhc) ya que no se disponia del ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Tomando en cuenta como “ground truth” el resultado del primer algoritmo, indique qué tan bueno es el rendimiento del segundo algoritmo (2 puntos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------- RENDIMIENTO DE LA PREDICCIÓN ---------\n",
      "ARI DHC:  0.10830975620901168\n",
      "AMI DHC:  0.17045236693013013\n",
      "NMI DHC:  0.1722395445649318\n"
     ]
    }
   ],
   "source": [
    "## el resultado del algoritmo de kmeans se tomó como ground truth y el de dhc como la predicción\n",
    "print('-------- RENDIMIENTO DE LA PREDICCIÓN ---------')\n",
    "groundTruth = clusters_k\n",
    "prediction = clusters_dhc\n",
    "##ARI\n",
    "ari_dhc = adjusted_rand_score(groundTruth,prediction)\n",
    "print(\"ARI DHC: \",ari_dhc)\n",
    "\n",
    "##AMI\n",
    "ami_dhc = adjusted_mutual_info_score(groundTruth,prediction)\n",
    "print(\"AMI DHC: \",ami_dhc)\n",
    "\n",
    "##NMI\n",
    "nmi_dhc = normalized_mutual_info_score(groundTruth,prediction)\n",
    "print(\"NMI DHC: \",nmi_dhc)\n",
    "\n",
    "##Como se puede observar los valores obtenidos estan cercanos a cero por tanto se concluye que el algoritmo de predicción( en este caso DHC) no dio un buen rendimiento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7d0076f7f30ce44e4ad8717c083ecd596b2b50f5b4c7eeebb5a285bcb845fc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
